{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as im\n",
    "from tensorflow.keras.preprocessing.image import array_to_img\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle\n",
    "import io\n",
    "import base64\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import mysql.connector as sqlc\n",
    "from nilearn import image\n",
    "from nibabel import nifti1\n",
    "from nibabel.viewers import OrthoSlicer3D\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import Model, Input, regularizers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D, Add, Conv2DTranspose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "notebook_path = os.path.abspath(\"preprocessing.ipynb\")\n",
    "scan_images = os.path.join(os.path.dirname(notebook_path), \"MRI_Scans_ATLAS\")\n",
    "train_data = []\n",
    "SIZE = 80\n",
    "\n",
    "# get images, resize it and store it into train data list in array format\n",
    "for filename in os.listdir(scan_images):\n",
    "    temp = os.path.join(scan_images, filename)\n",
    "    \n",
    "    # read .nii file\n",
    "    img = image.load_img(temp)\n",
    "    width,height,queue=img.dataobj.shape\n",
    "    num=1\n",
    "    \n",
    "    # save all the mri scans section into train data list\n",
    "    for i in range(0,queue-40,1):\n",
    "        img_arr=img.dataobj[:,:,i]\n",
    "        img_arr = cv2.resize(img_arr, (SIZE, SIZE))\n",
    "        train_data.append(img_to_array(img_arr))\n",
    "        num+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing the datas into value between 0 and 1\n",
    "x_train = np.reshape(train_data, (len(train_data), SIZE, SIZE, 1))\n",
    "x_train = x_train.astype('float32') / 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# the code is taken from https://towardsdatascience.com/image-super-resolution-using-convolution-neural-networks-and-auto-encoders-28c9eceadf90\n",
    "\n",
    "# split the train data into 2 section for training and validation\n",
    "train_x, val_x = train_test_split(x_train, test_size=0.2)\n",
    "\n",
    "# pixalate the images to make it low resolution image\n",
    "def pixalate_image(image, scale_percent = 40):\n",
    "    width = int(image.shape[1] * scale_percent / 100)\n",
    "    height = int(image.shape[0] * scale_percent / 100)\n",
    "    dim = (width, height)\n",
    "    \n",
    "    small_image = cv2.resize(image, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    width = int(small_image.shape[1] * 100 / scale_percent)\n",
    "    height = int(small_image.shape[0] * 100 / scale_percent)\n",
    "    dim = (width, height)\n",
    "    \n",
    "    low_res_image = cv2.resize(small_image, dim, interpolation =  cv2.INTER_AREA)\n",
    "    \n",
    "    return low_res_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the code is taken from https://towardsdatascience.com/image-super-resolution-using-convolution-neural-networks-and-auto-encoders-28c9eceadf90\n",
    "\n",
    "# pixalate the images in the training and validation lists\n",
    "train_x_px = []\n",
    "for i in range(train_x.shape[0]):\n",
    "    temp = pixalate_image(train_x[i,:,:,:])\n",
    "    train_x_px.append(temp)\n",
    "    \n",
    "train_x_px = np.array(train_x_px)\n",
    "\n",
    "val_x_px = []\n",
    "for i in range(val_x.shape[0]):\n",
    "    temp = pixalate_image(val_x[i,:,:,:])\n",
    "    val_x_px.append(temp)\n",
    "\n",
    "val_x_px = np.array(val_x_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 80, 80, 1)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 80, 80, 32)   320         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 80, 80, 32)   9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 40, 40, 32)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 40, 40, 64)   18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 40, 40, 64)   36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 20, 20, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 20, 20, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 20, 20, 128)  147584      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 10, 10, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 10, 10, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 10, 10, 256)  590080      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 256)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 5, 5, 512)    1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d (UpSampling2D)    (None, 10, 10, 512)  0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 10, 10, 256)  1179904     up_sampling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 10, 10, 256)  590080      conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 10, 10, 256)  0           conv2d_7[0][0]                   \n",
      "                                                                 conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 20, 20, 256)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 20, 20, 128)  295040      up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 20, 20, 128)  147584      conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 20, 20, 128)  0           conv2d_5[0][0]                   \n",
      "                                                                 conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 40, 40, 128)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 40, 40, 64)   73792       up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 40, 40, 64)   36928       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 40, 40, 64)   0           conv2d_3[0][0]                   \n",
      "                                                                 conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 80, 80, 64)   0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 80, 80, 32)   18464       up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 80, 80, 32)   9248        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 80, 80, 32)   0           conv2d_1[0][0]                   \n",
      "                                                                 conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 80, 80, 3)    867         add_3[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 4,703,747\n",
      "Trainable params: 4,703,747\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# creating the model for training\n",
    "\n",
    "# convolution 2d is used to filter the images\n",
    "\n",
    "# max pooling 2d is used to get the max value in the filtered images\n",
    "\n",
    "# regularizers is used to address over-fitting\n",
    "Input_img = Input(shape=(SIZE, SIZE, 1))\n",
    "\n",
    "x1 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(Input_img)\n",
    "x2 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x1)\n",
    "x3 = MaxPool2D(padding='same')(x2)\n",
    "\n",
    "x4 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x3)\n",
    "x5 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x4)\n",
    "x6 = MaxPool2D(padding='same')(x5)\n",
    "\n",
    "x7 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x6)\n",
    "x8 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x7)\n",
    "x9 = MaxPool2D(padding='same')(x8)\n",
    "\n",
    "x10 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x9)\n",
    "x11 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x10)\n",
    "x12 = MaxPool2D(padding='same')(x11)\n",
    "\n",
    "encoded = Conv2D(512, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x12)\n",
    "\n",
    "# Up sampling is used to increase the dimension of the images to smoothen the edges\n",
    "x13 = UpSampling2D()(encoded)\n",
    "x14 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x13)\n",
    "x15 = Conv2D(256, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x14)\n",
    "x16 = Add()([x11, x15])\n",
    "\n",
    "x17 = UpSampling2D()(x16)\n",
    "x18 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x17)\n",
    "x19 = Conv2D(128, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x18)\n",
    "x20 = Add()([x8, x19])\n",
    "\n",
    "x21 = UpSampling2D()(x20)\n",
    "x22 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x21)\n",
    "x23 = Conv2D(64, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x22)\n",
    "x24 = Add()([x5, x23])\n",
    "\n",
    "x25 = UpSampling2D()(x24)\n",
    "x26 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x25)\n",
    "x27 = Conv2D(32, (3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l1(10e-10))(x26)\n",
    "x28 = Add()([x2, x27])\n",
    "\n",
    "\n",
    "\n",
    "decoded = Conv2D(3, (3, 3), padding='same',activation='relu', kernel_regularizer=regularizers.l1(10e-10))(x28)\n",
    "\n",
    "autoencoder = Model(Input_img, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/176 [======================>.......] - ETA: 3s - loss: 0.0044 - accuracy: 0.0435"
     ]
    }
   ],
   "source": [
    "# training the model\n",
    "training = autoencoder.fit(train_x_px,train_x,\n",
    "            epochs=1,\n",
    "            validation_data=(val_x_px, val_x))\n",
    "print(\"DONE!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "autoencoder.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f666d4d48716>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mautoencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'model.h5'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# predictions = autoencoder.predict(val_x_px)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_model' is not defined"
     ]
    }
   ],
   "source": [
    "# load model\n",
    "autoencoder = load_model('model.h5')\n",
    "autoencoder.summary()\n",
    "# predictions = autoencoder.predict(val_x_px)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def database_connection(): \n",
    "    \"\"\"\n",
    "    This function is used to access the database which will then retrieve the images and convert it from binary data\n",
    "    into an image. It will then convert the image into an array and resize it to a appropriate size then normalize it\n",
    "    to a value between 0 and 1 which will later be used for prediction. The predicted value will be turned from array\n",
    "    into image and then the image will be converted into binary which will then be updated into the database.\n",
    "    \"\"\"\n",
    "    connection = sqlc.connect(host='localhost',\n",
    "                         database='web_app',\n",
    "                         user='root',\n",
    "                         password='Darrenlum1')\n",
    "    \n",
    "    MyCursor = connection.cursor()\n",
    "    \n",
    "    query = \"SELECT id FROM image_uploads WHERE id IS NOT NULL AND processed_image IS NULL\"\n",
    "    \n",
    "    MyCursor.execute(query)\n",
    "\n",
    "    data = MyCursor.fetchall()\n",
    "    for i in range(len(data)):\n",
    "        temp_id = data[i][0]\n",
    "        image = get_image(temp_id)\n",
    "\n",
    "        img_val = normalize_image(image, SIZE)\n",
    "\n",
    "        predictions = autoencoder.predict(img_val)\n",
    "\n",
    "        convert_to_image(predictions)\n",
    "\n",
    "        # change the image into binary\n",
    "        blob_value = open(\"preprocessed_image.jpg\", 'rb').read()\n",
    "\n",
    "        # update the image into database\n",
    "        sql = \"UPDATE image_uploads SET processed_image = %s WHERE id=%s\"\n",
    "        args = (blob_value, temp_id)\n",
    "        MyCursor.execute(sql, args)\n",
    "        connection.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(id):\n",
    "    \"\"\"\n",
    "    This function retrieve the image from database and convert it from binary data to pil image\n",
    "    \"\"\"\n",
    "    connection = sqlc.connect(host='localhost',\n",
    "                         database='web_app',\n",
    "                         user='root',\n",
    "                         password='Darrenlum1')\n",
    "    \n",
    "    MyCursor = connection.cursor()\n",
    "    \n",
    "    query = \"SELECT uploaded_image FROM image_uploads where id = %s\"\n",
    "    \n",
    "    args = (id,)\n",
    "    \n",
    "    MyCursor.execute(query, args)\n",
    "    \n",
    "    data = MyCursor.fetchall()\n",
    "    \n",
    "    image = data[0][0]\n",
    "    \n",
    "    binary_data = base64.b64decode(image)\n",
    "\n",
    "    image = im.open(io.BytesIO(binary_data))\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_image(image, size):\n",
    "    \"\"\"\n",
    "    This function resizes the image and convert it into array, then convert it into grayscale if it is not and normalizes the\n",
    "    data.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Resize the image\n",
    "    img = image.resize((SIZE, SIZE))\n",
    "    \n",
    "    # convert image into array\n",
    "    img_array = img_to_array(img)\n",
    "    \n",
    "    shp = img_array.shape\n",
    "    \n",
    "    # if the image is not in grayscale, change it to grayscale\n",
    "    if shp[2] != 1:\n",
    "        gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "        img_array = gray\n",
    "\n",
    "    # Normalize the image\n",
    "    standard_val = np.reshape(img_array, (1, SIZE, SIZE, 1))\n",
    "    standard_val = standard_val.astype('float32') / 255.\n",
    "    \n",
    "    return standard_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_image(predictions):\n",
    "    \"\"\"\n",
    "    This function convert the image array back to image resize it into an appropriate size and save the image as png\n",
    "    \"\"\"\n",
    "    img_pil = array_to_img(predictions[0])\n",
    "    \n",
    "    img_pil = img_pil.resize((720, 720))\n",
    "    img_pil.save(\"preprocessed_image.jpg\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000234044AA0D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "database_connection()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
